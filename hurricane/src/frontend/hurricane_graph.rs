use crate::common::bag::*;
use crate::common::chunk::*;
use crate::common::chunk_pool::*;
use crate::common::data_serializer::*;
use crate::frontend::hurricane_work_io::*;
use actix::prelude::*;
use futures::prelude::*;
use futures::sync::mpsc::*;
use futures::task;
use log::*;
use std::io;
use std::iter::Iterator;
use std::marker::PhantomData;

/// A `Filler` that fills `Chunk`s from input bags for the entire data pipeline to process.
///
///
/// This is the starting terminal for the data pipeline. It polls the `HurricaneWorkIO` actor,
/// which is the HurricaneWork <=> Storage nodes network layer.
///
///
/// The polling is done by firstly sending a request via Actix message to the `HurricaneWorkIO` actor,
/// which will redirect the request to the storage nodes for data `Chunk`s. The `Chunk` will then be sent back
/// via `futures::sync::mpsc::channel`. This filler contains the `Receiver` side of the channel, and it
/// will continue polling the `Sender` side of the channel for `Chunk`s.
///
///
/// Done, but not integrated into the system yet.
pub struct Filler<F>
where
    F: Format + 'static,
    F::Item: Send,
{
    filler_id: usize,
    bag: Bag,
    _phantom: PhantomData<F>,
    rx: Receiver<Option<Chunk>>,
    hwio_address: Recipient<HurricaneWorkIOChunkMessage>,
    request_sent: bool,
}

impl<F> Filler<F>
where
    F: Format + 'static,
    F::Item: Send,
{
    pub fn from(
        filler_id: usize,
        bag: Bag,
        rx: Receiver<Option<Chunk>>,
        hwio_address: Recipient<HurricaneWorkIOChunkMessage>,
    ) -> Filler<F> {
        Filler {
            filler_id,
            bag,
            _phantom: PhantomData,
            rx,
            hwio_address,
            request_sent: false,
        }
    }
}

impl<F> Stream for Filler<F>
where
    F: Format + 'static,
    F::Item: Send,
{
    type Item = Box<dyn Iterator<Item = F::Item> + Send>;
    type Error = io::Error;

    fn poll(&mut self) -> Result<Async<Option<Self::Item>>, Self::Error> {
        if !self.request_sent {
            // If request not sent yet, send the request
            self.hwio_address
                .try_send(HurricaneWorkIOChunkMessage::FillerGetChunk(
                    self.filler_id,
                    self.bag.clone(),
                ))
                .unwrap();

            self.request_sent = true;

            task::current().notify();
            return Ok(Async::NotReady);
        } else {
            // Request already sent

            // Poll the rx
            match self.rx.poll() {
                Ok(status) => match status {
                    Async::Ready(outer_chunk_result) => {
                        match outer_chunk_result {
                            Some(inner_chunk_result) => {
                                match inner_chunk_result {
                                    Some(chunk) => {
                                        // Received a chunk, convert it into an iter using the provided formatter.
                                        let chunk_it = chunk.into_iter::<F>();

                                        self.request_sent = false;
                                        return Ok(Async::Ready(Some(chunk_it)));
                                    }
                                    None => {
                                        // No more chunks, this is message generated by the
                                        // actual sender, I trust this.
                                        self.request_sent = false;
                                        return Ok(Async::Ready(None));
                                    }
                                }
                            }
                            None => {
                                // No more chunks, this is message generated by the channel,
                                // I don't trust it.
                                self.request_sent = false;
                                return Ok(Async::Ready(None));
                            }
                        }
                    }
                    Async::NotReady => {
                        return Ok(Async::NotReady);
                    }
                },
                Err(_) => {
                    return Err(io::Error::new(
                        io::ErrorKind::Other,
                        "Unexpected error in Filler.",
                    ));
                }
            }
        }
    }
}

pub struct Drainer<F>
where
    F: Format + 'static,
    F::Item: Send + Clone,
{
    drainer_id: usize,
    bag: Bag,
    _phantom: PhantomData<F>,
    tx: Sender<(Bag, Chunk)>,

    chunk_pusher: Option<Box<dyn Pusher<Item = F::Item, InnerContainer = Buffer> + Send>>,
    dont_pack: bool,
}

impl<F> Drainer<F>
where
    F: Format + 'static,
    F::Item: Send + Clone,
{
    pub fn from(
        drainer_id: usize,
        bag: Bag,
        tx: Sender<(Bag, Chunk)>,
        dont_pack: bool,
    ) -> Drainer<F> {
        Drainer {
            drainer_id,
            bag,
            _phantom: PhantomData,
            tx,
            chunk_pusher: Some(ChunkPool::allocate().into_pusher::<F>()),
            dont_pack,
        }
    }
}

impl<F> Sink for Drainer<F>
where
    F: Format + 'static,
    F::Item: Send + Clone,
{
    type SinkItem = F::Item;
    type SinkError = io::Error;

    fn start_send(
        &mut self,
        item: Self::SinkItem,
    ) -> Result<AsyncSink<Self::SinkItem>, Self::SinkError> {
        match self.chunk_pusher.as_mut() {
            Some(pusher) => {
                match pusher.put(item.clone()) {
                    Some(_) => {
                        // Good, the item is pushed into the chunk.

                        if self.dont_pack {
                            let chunk = Chunk::from_pusher(self.chunk_pusher.take().unwrap());

                            match self.tx.start_send((self.bag.clone(), chunk)) {
                                Err(e) => panic!("Unexpected error in Drainer. {}", e),
                                Ok(status) => match status {
                                    AsyncSink::NotReady((_, _)) => {
                                        warn!(
                                            "Drainer {} cannot send chunk! Sender: {:?}. Try again later.",
                                            self.drainer_id, self.tx
                                        );

                                        // Return to the initial state, ie. empty chunk.
                                        self.chunk_pusher =
                                            Some(ChunkPool::allocate().into_pusher::<F>());
                                        task::current().notify();
                                        return Ok(AsyncSink::NotReady(item));
                                    }
                                    AsyncSink::Ready => {
                                        // Successfully sent.
                                        return Ok(AsyncSink::Ready);
                                    }
                                },
                            }
                        }

                        //println!("Successfully put into pusher.");
                        return Ok(AsyncSink::Ready);
                    }
                    None => {
                        // Oh, the chunk is full, pack and send the chunk.
                        // Current item is rejected.
                        //println!("Chunk Full, try to send it.");

                        let chunk = Chunk::from_pusher(self.chunk_pusher.take().unwrap());

                        match self.tx.start_send((self.bag.clone(), chunk)) {
                            Err(e) => panic!("Unexpected error in Drainer. {}", e),
                            Ok(status) => match status {
                                AsyncSink::NotReady((_, chunk)) => {
                                    warn!(
                                        "Drainer {} cannot send chunk! Sender: {:?}. Try again later.",
                                        self.drainer_id, self.tx
                                    );

                                    // Put the packed chunk back.
                                    self.chunk_pusher = Some(chunk.into_pusher::<F>());
                                    task::current().notify();
                                    return Ok(AsyncSink::NotReady(item));
                                }
                                AsyncSink::Ready => {
                                    // Current chunk is sent, reject current item
                                    //println!("Successfully sent chunk.");
                                    task::current().notify();
                                    return Ok(AsyncSink::NotReady(item));
                                }
                            },
                        }
                    }
                }
            }
            None => {
                // The previous chunk is still on its way to destination
                //println!("Waiting for previous chunk");
                match self.poll_complete() {
                    Err(_) => panic!("Unexpected error in Drainer."),
                    Ok(_status) => {
                        task::current().notify();
                        Ok(AsyncSink::NotReady(item))
                    }
                }
            }
        }
    }

    fn poll_complete(&mut self) -> Result<Async<()>, Self::SinkError> {
        //println!("poll_complete");
        match self.chunk_pusher {
            None => match self.tx.poll_complete() {
                Ok(status) => match status {
                    Async::Ready(_) => {
                        //println!("channel clear.");
                        // The previous chunk was sent, create a new chunk for use
                        self.chunk_pusher = Some(ChunkPool::allocate().into_pusher::<F>());
                        Ok(Async::Ready(()))
                    }
                    Async::NotReady => {
                        //println!("waiting channel.");
                        task::current().notify();
                        Ok(Async::NotReady)
                    }
                },
                Err(_) => panic!("Unexpected error in Drainer."),
            },
            Some(_) => {
                // The previous chunk was already sent, and current chunk being built-up
                // should not be sent now.
                //println!("no chunk on air.");
                Ok(Async::Ready(()))
            }
        }
    }

    fn close(&mut self) -> Result<Async<()>, Self::SinkError> {
        match self.chunk_pusher.take() {
            None => match self.tx.close() {
                Ok(status) => match status {
                    Async::Ready(_) => Ok(Async::Ready(())),
                    Async::NotReady => {
                        task::current().notify();
                        Ok(Async::NotReady)
                    }
                },
                Err(_) => panic!("Unexpected error in Drainer."),
            },
            Some(pusher) => {
                // Forcefully send this chunk
                let chunk = Chunk::from_pusher(pusher);
                if chunk.get_chunk_size() != 0 {
                    // Send this chunk if it is not empty.
                    match self.tx.start_send((self.bag.clone(), chunk)) {
                        Err(e) => panic!("Unexpected error in Drainer. {}", e),
                        Ok(status) => match status {
                            AsyncSink::NotReady((_, chunk)) => {
                                warn!(
                                    "Drainer {} cannot send chunk! Sender: {:?}. Try again later.",
                                    self.drainer_id, self.tx
                                );

                                // Put the packed chunk back.
                                self.chunk_pusher = Some(chunk.into_pusher::<F>());
                            }
                            AsyncSink::Ready => {
                                // Current chunk is sent, need to come back to poll.
                            }
                        },
                    }
                    task::current().notify();
                    Ok(Async::NotReady)
                } else {
                    // Do not send this chunk if it is empty.
                    Ok(Async::Ready(()))
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::common::primitive_serializer::*;
    use crate::frontend::bag_io_mock::*;
    use std::collections::HashMap;
    use std::thread;
    use std::time::{Duration, Instant};

    #[test]
    fn filler_connection() {
        let sys = System::new("Hurricane-UnitTest");

        // create channel for delivering chunks to filler
        let (sender, receiver) = channel::<Option<Chunk>>(0);

        // generate input chunks for filler
        let chunk = ChunkPool::allocate();
        let num_i64 = chunk.get_chunk_size() / std::mem::size_of::<i64>();
        let mut pu = chunk.into_pusher::<I64Format>();
        (0..num_i64).for_each(|i| assert_eq!(Some(()), pu.put(i as i64)));
        let chunk = Chunk::from_pusher(pu);
        let chunks: Vec<Chunk> = (0..400).map(|_| chunk.clone()).collect();

        // answer to compare against
        let answer: Vec<i64> = (0..num_i64 as i64).collect();

        // start the data provider actor
        let data_provider = DataProvider::spawn(
            (false, false),
            None,
            vec![sender],
            vec![],
            chunks,
            DataProviderChecker::None,
        );

        // construct the filler
        let filler = InBag::from(
            Bag::new(),
            vec![receiver],
            data_provider.clone().recipient(),
        )
        .into_fillers::<I64Format>()
        .pop()
        .unwrap();

        // the actual task on filler
        let task = filler
            .map_err(|_| ())
            .for_each(move |it| {
                let v: Vec<i64> = it.collect();
                assert_eq!(v, answer.clone());
                futures::future::ok(())
            })
            .map(move |_| data_provider.try_send(Stop).unwrap());

        Arbiter::spawn(task);

        sys.run();
    }

    #[test]
    fn single_pipe_single_fanin_single_fanout() {
        let start_time = Instant::now();

        let num_chunks = 80;
        let sys = System::new("Hurricane-UnitTest");

        // create channel for delivering chunks to filler
        let (filler_sender, filler_receiver) = channel::<Option<Chunk>>(0);
        // create channel for delivering chunks to drainer
        let (drainer_sender, drainer_receiver) = channel::<(Bag, Chunk)>(0);

        // generate input chunks for filler
        let chunk = ChunkPool::allocate();
        let num_i64 = chunk.get_chunk_size() / std::mem::size_of::<i64>();
        let mut pu = chunk.into_pusher::<I64Format>();
        (0..num_i64).for_each(|i| assert_eq!(Some(()), pu.put(i as i64)));
        let chunk = Chunk::from_pusher(pu);
        let chunks: Vec<Chunk> = (0..num_chunks).map(|_| chunk.clone()).collect();

        // answer to compare against
        let ans_chunk = ChunkPool::allocate();
        let num_i64 = ans_chunk.get_chunk_size() / std::mem::size_of::<i64>();
        let mut ans_pu = ans_chunk.into_pusher::<I64Format>();
        (0..num_i64)
            .map(|x| x * 2)
            .for_each(|i| assert_eq!(Some(()), ans_pu.put(i as i64)));
        let ans_chunk = Chunk::from_pusher(ans_pu);
        let mut ans_chunks: HashMap<Bag, Vec<Chunk>> = HashMap::new();
        assert!(ans_chunks
            .insert(
                Bag::new(),
                (0..num_chunks).map(|_| ans_chunk.clone()).collect(),
            )
            .is_none());

        // start the data provider actor
        let data_provider = DataProvider::spawn(
            (false, false),
            Some(num_chunks),
            vec![filler_sender],
            vec![drainer_receiver],
            chunks,
            DataProviderChecker::Answer(ans_chunks),
        );

        let task = InBag::from(Bag::new(), vec![filler_receiver], data_provider.recipient())
            .execute::<I64Format, _, _>(|st| st.map(|x| x * 2))
            .into_bag(
                PhantomData::<I64Format>,
                OutBag::from(Bag::new(), drainer_sender, false),
            )
            .pop()
            .unwrap()
            .map_err(|_| ())
            .map(|_| ());

        Arbiter::spawn(task);

        sys.run();
        println!("Elapsed time: {:?}.", start_time.elapsed());
    }

    #[test]
    fn multi_pipe_single_fanin_single_fanout() {
        // DataProvider is running on a separator thread! Will block if spawned in main thread!
        // Plus worker threads.

        // num worker threads
        for i in 1..9 {
            let start_time = Instant::now();

            let num_chunks = 20;
            let num_threads = i;
            println!("\nWorkers runing on {} threads.", num_threads);
            let sys = System::new("Hurricane-UnitTest");

            // create channel for delivering chunks to filler
            let (filler_senders, filler_receivers): (Vec<_>, Vec<_>) = (0..num_threads)
                .map(|_| channel::<Option<Chunk>>(0))
                .unzip();

            // create channel for delivering chunks to drainer
            let (drainer_sender, drainer_receiver) = channel::<(Bag, Chunk)>(0);

            // generate input chunks for filler
            let chunk = ChunkPool::allocate();
            let num_i64 = chunk.get_chunk_size() / std::mem::size_of::<i64>();
            let mut pu = chunk.into_pusher::<I64Format>();
            (0..num_i64).for_each(|i| assert_eq!(Some(()), pu.put(i as i64)));
            let chunk = Chunk::from_pusher(pu);
            let chunks: Vec<Chunk> = (0..num_chunks).map(|_| chunk.clone()).collect();

            // answer to compare against
            let ans_chunk = ChunkPool::allocate();
            let num_i64 = ans_chunk.get_chunk_size() / std::mem::size_of::<i64>();
            let mut ans_pu = ans_chunk.into_pusher::<I64Format>();
            (0..num_i64)
                .map(|x| x * 2)
                .for_each(|i| assert_eq!(Some(()), ans_pu.put(i as i64)));
            let ans_chunk = Chunk::from_pusher(ans_pu);
            let mut ans_chunks: HashMap<Bag, Vec<Chunk>> = HashMap::new();
            assert!(ans_chunks
                .insert(
                    Bag::new(),
                    (0..num_chunks).map(|_| ans_chunk.clone()).collect(),
                )
                .is_none());

            // start the data provider actor
            let data_provider = DataProvider::spawn(
                (false, false),
                Some(num_chunks),
                filler_senders,
                vec![drainer_receiver],
                chunks,
                DataProviderChecker::Answer(ans_chunks),
            );

            // Do the job
            let threads: Vec<_> =
                InBag::from(Bag::new(), filler_receivers, data_provider.recipient())
                    .execute::<I64Format, _, _>(|st| st.map(|x| x * 2))
                    .into_bag(
                        PhantomData::<I64Format>,
                        OutBag::from(Bag::new(), drainer_sender.clone(), false),
                    )
                    .into_iter()
                    .enumerate()
                    .map(|(_thread_id, stream)| {
                        let task = stream.map_err(|_| ()).map(|_| ());

                        thread::spawn(move || {
                            tokio::run(task);
                        })
                    })
                    .collect();

            sys.run();

            threads
                .into_iter()
                .for_each(|thread_handle| thread_handle.join().unwrap());

            println!("Elapsed time: {:?}.", start_time.elapsed());
        }
    }

    #[test]
    fn multi_pipe_single_fanin_multi_fanout() {
        // DataProvider is running on a separator thread! Will block if spawned in main thread!
        // Plus worker threads.

        // num worker threads
        for i in 1..9 {
            let start_time = Instant::now();

            let num_chunks = 20;
            let num_threads = i;
            println!("\nWorkers runing on {} threads.", num_threads);
            let sys = System::new("Hurricane-UnitTest");

            // create channel for delivering chunks to filler
            let (filler_senders, filler_receivers): (Vec<_>, Vec<_>) = (0..num_threads)
                .map(|_| channel::<Option<Chunk>>(0))
                .unzip();

            // create channel for delivering chunks to drainer
            let (drainer_sender_a, drainer_receiver_a) = channel::<(Bag, Chunk)>(0);
            let (drainer_sender_b, drainer_receiver_b) = channel::<(Bag, Chunk)>(0);

            // generate input chunks for filler
            let chunk = ChunkPool::allocate();
            let num_i64 = chunk.get_chunk_size() / std::mem::size_of::<i64>();
            let mut pu = chunk.into_pusher::<I64Format>();
            (0..num_i64).for_each(|i| assert_eq!(Some(()), pu.put(i as i64)));
            let chunk = Chunk::from_pusher(pu);
            let chunks: Vec<Chunk> = (0..num_chunks).map(|_| chunk.clone()).collect();

            // start the data provider actor
            let data_provider = DataProvider::spawn(
                (false, false),
                None,
                filler_senders,
                vec![drainer_receiver_a, drainer_receiver_b],
                chunks,
                DataProviderChecker::CustomerChecker(Box::new(move |mut chunks| {
                    chunks.drain().for_each(move |(bag, chunks)| {
                        if bag == Bag::from("bag-a") {
                            chunks.into_iter().for_each(|chunk| {
                                assert!(chunk
                                    .into_iter::<I64Format>()
                                    .all(move |x| (x as usize) < num_i64))
                            });
                        } else {
                            chunks.into_iter().for_each(move |chunk| {
                                assert!(chunk
                                    .into_iter::<I64Format>()
                                    .all(move |x| (x as usize) >= num_i64))
                            });
                        }
                    })
                })),
            );

            // Do the job
            let threads: Vec<_> = InBag::from(
                Bag::new(),
                filler_receivers,
                data_provider.clone().recipient(),
            )
            .execute::<I64Format, _, _>(|st| st.map(|x| x * 2))
            .into_bags(
                PhantomData::<I64Format>,
                vec![
                    OutBag::from(Bag::from("bag-a"), drainer_sender_a.clone(), false),
                    OutBag::from(Bag::from("bag-b"), drainer_sender_b.clone(), false),
                ],
                move |x| if (x as usize) < num_i64 { 0 } else { 1 },
            )
            .into_iter()
            .enumerate()
            .map(move |(thread_id, stream)| {
                let data_provider_clone = data_provider.clone();
                let task = stream.map_err(|_| ()).map(move |_| {
                    if thread_id == num_threads - 1 {
                        // The future on the last thread must wait all
                        // other futures to complete before killing the DataProvider.
                        // Pick a sleep time yourself.
                        thread::sleep(Duration::from_secs(1));
                        data_provider_clone.try_send(Stop).unwrap();
                    }
                });

                thread::spawn(move || {
                    tokio::run(task);
                })
            })
            .collect();

            sys.run();

            // Unfortunately, there is no deterministic way to notify DataProducer
            // actor to kill itself.
            threads
                .into_iter()
                .for_each(|thread_handle| thread_handle.join().unwrap());

            println!("Elapsed time: {:?}.", start_time.elapsed());
        }
    }
}
